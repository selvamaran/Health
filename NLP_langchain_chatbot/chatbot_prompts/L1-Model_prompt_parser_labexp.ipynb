{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5fd2f5b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb32bb7b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "196ebea4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1418c2b",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt,model='gpt-3.5-turbo'):\n",
    "    messages = [{'role':'user','content':prompt}]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "    model = model,\n",
    "    messages = messages,\n",
    "    temperature = 0.0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message[\"content\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b39167e7",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is an artificial intelligence research laboratory consisting of the for-profit corporation OpenAI LP and its parent company, the non-profit OpenAI Inc. The organization aims to develop and promote friendly AI for the betterment of humanity. OpenAI conducts research in various fields of AI, including natural language processing, robotics, and reinforcement learning. It also develops and releases open-source AI tools and platforms to encourage collaboration and innovation in the field. OpenAI was founded in 2015 by a group of tech luminaries, including Elon Musk, Sam Altman, and Greg Brockman.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_completion('what is openai')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08d9608c",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "def get_completion_full_ouput(prompt, model = 'gpt-3.5-turbo'):\n",
    "    \n",
    "    messages = [{'role':'user','content':prompt}]\n",
    "    \n",
    "    response=openai.ChatCompletion.create(\n",
    "    model=model,\n",
    "    messages = messages,\n",
    "    temperature = 0.0,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e025bd61",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# type(output),type(output.choices),type(output.choices[0]),type(output.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6046e566",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#  output.choices[0].message['role']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7fb959a",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e2dd441",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f613f951",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebf2d977",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am quite upset that my blender lid came off and caused my smoothie to splatter all over my kitchen walls. Additionally, the warranty does not cover the cost of cleaning up the mess. Would you be able to assist me, please? Thank you kindly.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60b8378c",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "template_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f866aa9",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0bd791b0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb66bc81",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd9b5018",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3708e1a",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "326f0e3d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6984c702",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35ef5511",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ec7c8f60",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie. To add to my frustration, the warranty doesn't cover the cost of cleaning up my kitchen. Can you please help me out, friend?\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)\n",
    "customer_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f08842d2",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie. To add to my frustration, the warranty doesn't cover the cost of cleaning up my kitchen. Can you please help me out, friend?\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "current-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "final-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "golden-integral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Monday\n",
      "  \n",
      "- 10 minutes of warmup jogging \n",
      "- 20 minutes of HIIT sprints (20 seconds sprint, 40 seconds walking)\n",
      "- 10 minutes of jogging as a cool-down \n",
      "\n",
      "Tuesday \n",
      "\n",
      "- 10 minutes of jog warmup \n",
      "- 30 minutes of hill sprints \n",
      "- 10 minutes of jogging as a cool-down \n",
      "\n",
      "Wednesday \n",
      "\n",
      "- 10 minutes of jog warmup \n",
      "- 20 minutes of Tabata (20 seconds of sprint, 10 seconds of rest)\n",
      "- 10 minutes of jog cool-down \n",
      "\n",
      "Thursday \n",
      "\n",
      "- 10 minutes of jog warmup \n",
      "- 20 minutes of interval training (1 minute of sprinting, 1 minute of walking) \n",
      "- 10 minutes of jog cool-down \n",
      "\n",
      "Friday \n",
      "\n",
      "- 10 minutes of jog warmup \n",
      "- 15 minutes of stair climbing \n",
      "- 10 minutes of jog cool-down \n",
      "\n",
      "Saturday \n",
      "\n",
      "- 10 minutes of jog warmup \n",
      "- 30 minutes of bike riding \n",
      "- 10 minutes of jog cool-down \n",
      "\n",
      "Sunday \n",
      "\n",
      "- 10 minutes of jog warmup \n",
      "- 15 minutes of cross-country running \n"
     ]
    }
   ],
   "source": [
    "text = \"Suggest a personalized workout routine each day for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extra-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "higher-barrel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 47\n",
      "\tPrompt Tokens: 4\n",
      "\tCompletion Tokens: 43\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00094\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm(\"Tell me a joke\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moved-romance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did one ocean say to the other ocean?\\nA: Nothing, they just waved.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-missouri",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
